{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "import os\n",
    "import numpy\n",
    "from scripts.utils import read_gold_data\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_name = \"data-release\" # set data path name!\n",
    "\n",
    "data = read_gold_data(data_path_name)\n",
    "corpus = data[\"corpus\"]\n",
    "baseline_queries_train = data[\"baseline\"][\"train\"]\n",
    "baseline_queries_dev = data[\"baseline\"][\"dev\"]\n",
    "perspective_queries_train = data[\"perspective\"][\"train\"]\n",
    "perspective_queries_dev = data[\"perspective\"][\"dev\"]\n",
    "\n",
    "# uncomment when using test set\n",
    "# baseline_queries_test = data[\"baseline\"][\"test\"]\n",
    "# perspective_queries_test = data[\"perspective\"][\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = baseline_queries_dev\n",
    "folder_name = \"final-scores\" # set folder name\n",
    "scenario = \"surprise\\\\baseline\" # set (subfolder and) scenario (you can also just set the full filename below if you want)\n",
    "prediction = pd.read_json(f\"{folder_name}\\\\{scenario}_similarity_scores.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_topics = corpus[\"topic\"].values\n",
    "prediction_topics = prediction[\"topic\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_d_relevance = [[a[b] / 50 if b in a else 0 for b in corpus_topics] for a in prediction_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(two_d_relevance)):\n",
    "    row = two_d_relevance[i]\n",
    "    scores.append({\n",
    "        'query_id': queries[\"query_id\"].values[i],\n",
    "        'topic_scores': row\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_json(f\"{folder_name}\\\\{scenario}_topic_scores.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
